{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data, Preprocessing\n",
    "\n",
    "The dataset we have to feed consist of 'Tweets' according to the kaggle guide,\n",
    "which means that there sould be lots of 'cooloquial expressions','hashtags','links',etc.\n",
    "\n",
    "Thus, we have to \"clean\" this data(I mean, \"text\") before we feed it to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('Data/train.csv')\n",
    "test = pd.read_csv('Data/test.csv')\n",
    "train_len = len(train) # we should record it to split all_data into train,test again\n",
    "\n",
    "all_data = pd.concat([train,test]) # for preprocessing and tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "# Cleaning Functions\n",
    "def remove_tag(text):\n",
    "    tag = re.compile(r'@\\S+')\n",
    "    return tag.sub(r'',text)\n",
    "\n",
    "def remove_URL(text):\n",
    "    # http:... / https:... / www... \n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return re.sub(url,'',text)\n",
    "\n",
    "def remove_html(text):\n",
    "    # < > / ( )\n",
    "    html = re.compile(r'<[^>]+>|\\([^)]+\\)')\n",
    "    return html.sub(r'',text)\n",
    "\n",
    "def remove_punct(text):\n",
    "    # ['!','\"','$','%','&',\"'\",'(',')','*',\n",
    "    # '+',',','-','.','/',':',';','<','=',\n",
    "    # '>','?','@','[','\\\\',']','^','_','`',\n",
    "    # '{','|','}','~']\n",
    "    punctuations = list(string.punctuation)\n",
    "    table = str.maketrans('', '', ''.join(punctuations))\n",
    "    return text.translate(table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "If you want to correct some misspelled words, you can try below also.\n",
    "But I supposed that there must be some other misspelled also in \"test set\".\n",
    "\n",
    "I thought, if I corrected these words in training process, there would be a chacne that\n",
    "the model couldn't bear some \"noises\"(misspelled words).\n",
    "\n",
    "So, In my opinion, this task of correction must be accompanied with \"result analysis\".\n",
    "'''\n",
    "# from spellchecker import SpellChecker\n",
    "\n",
    "# spell = SpellChecker()\n",
    "# def correct_spellings(text):\n",
    "#     corrected_text = []\n",
    "#     misspelled_words = spell.unknown(text.split())\n",
    "#     for word in text.split():\n",
    "#         if word in misspelled_words:\n",
    "#             corrected_text.append(spell.correction(word))\n",
    "#         else:\n",
    "#             corrected_text.append(word)\n",
    "#     return \" \".join(corrected_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/chanmuzi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/chanmuzi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Nltk is used to remove stopwords and punktuations.\n",
    "\n",
    "Stopwords are words that are used frequently, but have no 'semantic' meaning,\n",
    "which could affact model training (I mean, negatively).\n",
    "\n",
    "And punctuations like '.', ',' also seems they don't have meaningful effect of interpreting sentences.\n",
    "'''\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['cleaned'] = all_data['text'].apply(lambda x:remove_tag(x))\n",
    "all_data['cleaned'] = all_data['cleaned'].apply(lambda x: remove_URL(x))\n",
    "all_data['cleaned'] = all_data['cleaned'].apply(lambda x: remove_html(x))\n",
    "all_data['cleaned'] = all_data['cleaned'].apply(lambda x: remove_punct(x))\n",
    "all_data['cleaned'] = all_data['cleaned'].apply(lambda x: x.lower()) # lowering\n",
    "all_data['cleaned'] = all_data['cleaned'].apply(lambda x: word_tokenize(x)) # split sentence into words list\n",
    "# exclude stop words and make them a sentence again\n",
    "all_data['cleaned'] = all_data['cleaned'].apply(lambda x: ' '.join([word for word in x if word not in stop]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember we have combined train and test set into one \"all_data\"\n",
    "train_data,test_data = all_data[:train_len],all_data[train_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class TweetDataset(Dataset):\n",
    "    def __init__(self,df,label,tokenizer):\n",
    "        self.df = df # Pandas.DataFrame\n",
    "        self.label = label # True: train,valid / False: test\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df) # number of samples\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        text = self.df.loc[idx]['text'] # extracting text from each row\n",
    "\n",
    "        encoded_dict = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=84, # given to the max_length of tokenized text\n",
    "            return_tensors='pt', # PyTorch\n",
    "            return_attention_mask=True, # We should put it into the model\n",
    "        )\n",
    "        '''\n",
    "        The model BERT has two positional(mandatory) arguments,\n",
    "        \"input_ids\" and \"attention_mask\".\n",
    "\n",
    "        In the process of train/valid, we already have labels(answers),\n",
    "        but in case of test, we don't.\n",
    "        '''\n",
    "        if self.label:\n",
    "            labels = self.df.loc[idx]['target']\n",
    "            # [batch,1,max_len(84)] -> [batch,max_len]\n",
    "            return {'input_ids':encoded_dict['input_ids'].squeeze(),\n",
    "                    'attention_mask':encoded_dict['attention_mask'].squeeze(),\n",
    "                    # Our loss_fn wants it to be a \"long tensor\", so it will be changed\n",
    "                    'labels':torch.tensor(labels,dtype=torch.int).unsqueeze(dim=0)}\n",
    "        else:\n",
    "            # [batch,1,max_len(84)] -> [batch,max_len]\n",
    "            return {'input_ids':encoded_dict['input_ids'].squeeze(),\n",
    "                    'attention_mask':encoded_dict['attention_mask'].squeeze()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "model_name = 'bert-base-uncased' # If possible, use \"bert-large-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "train_dataset = TweetDataset(train_data,True,tokenizer)\n",
    "test_dataset = TweetDataset(test_data,False,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6090 train samples\n",
      "1523 valid samples\n",
      "3263 test samples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "train_size = int(0.8 * len(train_dataset)) # train:valid = 8:2\n",
    "valid_size = len(train_dataset) - train_size\n",
    "\n",
    "train_dataset,valid_dataset = random_split(train_dataset,[train_size,valid_size])\n",
    "\n",
    "print(f'{len(train_dataset)} train samples')\n",
    "print(f'{len(valid_dataset)} valid samples')\n",
    "print(f'{len(test_dataset)} test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "'''\n",
    "DataLoader in torch is useful tools for model to get data \"in Batch\".\n",
    "\n",
    "So, the steps we have to take are like this, \n",
    "\"Load CSV file -> make Dataset(in torch.utils.data) -> make DataLoader\"\n",
    "\n",
    "Please pay attention to the fact that I only \"shuffled\" train set, not valid/test set.\n",
    "'''\n",
    "train_dataloader = DataLoader(train_dataset,batch_size=32,shuffle=True,pin_memory=True)\n",
    "valid_dataloader = DataLoader(valid_dataset,batch_size=32,shuffle=False,pin_memory=True)\n",
    "test_dataloader = DataLoader(test_dataset,batch_size=1,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "You can give some info to the model,tokenizer or something\n",
    "instead of using arguments below.\n",
    "\n",
    "But, I prefer to use it because it makes experiment more easier.\n",
    "I mean, there is only one cell I have to change for an experiment\n",
    "making some differences in settings.\n",
    "'''\n",
    "\n",
    "configs = {\n",
    "    'model_name':'bert-base-uncased',\n",
    "    'num_labels':2,\n",
    "    'batch_size':32,\n",
    "    'epochs':4,\n",
    "    'learning_rate':5e-6,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "# Never Detach Tensor during forward\n",
    "class TweetsModel(nn.Module):\n",
    "    '''\n",
    "    To be honest, under the setting like this, there is no need to inherit.\n",
    "    It's because I used \"BertForSequenceClassification\" which has final layer\n",
    "    that is composed of \"hidden size 2\" for binary classification.\n",
    "\n",
    "    So, you can think of this unnecessary inheritance is kind of \"practice\" for myself :)\n",
    "    '''\n",
    "    def __init__(self,model_name):\n",
    "        super().__init__()\n",
    "        self.model = BertForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "    def forward(self,input_ids,attention_mask):\n",
    "        output = self.model(input_ids=input_ids,attention_mask=attention_mask)\n",
    "        logits = output.logits\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU is turning on..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "    print('GPU is running on..')\n",
    "else: \n",
    "    device = 'cpu'\n",
    "    print('CPU is running on..')\n",
    "\n",
    "'''\n",
    "You must check your accelerator setting in the right pannel.\n",
    "'''\n",
    "model = TweetsModel(configs['model_name']).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "# (y_pred,y_label)\n",
    "import torch.nn as nn\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "from transformers import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                lr=6e-6,\n",
    "                eps=1e-8,\n",
    "                no_deprecation_warning=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric for validation\n",
    "# f1_score(y_label,y_pred)\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "metric = f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc,os\n",
    "from tqdm.auto import tqdm # visualizing tool for progress\n",
    "\n",
    "# They will be used to pick the best model.pt given to the valid loss\n",
    "best_model_epoch, valid_loss_values = [],[] \n",
    "valid_loss_min = [1] # arbitrary loss I set here\n",
    "\n",
    "def train(model,device,train_dataloader,valid_dataloader,epochs,loss_fn,optimizer,metric):\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        gc.collect() # memory cleaning\n",
    "        model.train()\n",
    "\n",
    "        train_loss = 0\n",
    "        train_step = 0\n",
    "        pbar = tqdm(train_dataloader)\n",
    "\n",
    "        for batch in pbar: # you can also write like \"for batch in tqdm(train_dataloader\"\n",
    "            optimizer.zero_grad() # initialize\n",
    "            train_step += 1\n",
    "\n",
    "            train_input_ids = batch['input_ids'].to(device)\n",
    "            train_attention_mask = batch['attention_mask'].to(device)\n",
    "            train_labels = batch['labels'].squeeze().to(device).long()\n",
    "            \n",
    "            # You can refer to the class \"TweetsModel\" for understand \n",
    "            # what would be logits\n",
    "            logits = model(train_input_ids, train_attention_mask).to(device)\n",
    "            predictions = torch.argmax(logits, dim=1) # get an index from larger one\n",
    "            detached_predictions = predictions.detach().cpu().numpy()\n",
    "            \n",
    "            loss = loss_fn(logits, train_labels)\n",
    "            loss.backward() \n",
    "            optimizer.step()\n",
    "            model.zero_grad()\n",
    "\n",
    "            train_loss += loss.detach().cpu().numpy().item()\n",
    "\n",
    "            pbar.set_postfix({'train_loss':train_loss/train_step})\n",
    "        pbar.close()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "\n",
    "            valid_loss = 0\n",
    "            valid_step = 0\n",
    "            total_valid_score = 0\n",
    "\n",
    "            y_pred = [] # for getting f1_score that is a metric of the competition\n",
    "            y_true = []\n",
    "\n",
    "            pbar = tqdm(valid_dataloader)\n",
    "            for batch in pbar:\n",
    "                valid_step += 1\n",
    "\n",
    "                valid_input_ids = batch['input_ids'].to(device)\n",
    "                valid_attention_mask = batch['attention_mask'].to(device)\n",
    "                valid_labels = batch['labels'].squeeze().to(device).long()\n",
    "\n",
    "                logits = model(valid_input_ids, valid_attention_mask).to(device)\n",
    "                predictions = torch.argmax(logits, dim=1)\n",
    "                detached_predictions = predictions.detach().cpu().numpy()\n",
    "                \n",
    "                loss = loss_fn(logits, valid_labels)\n",
    "                valid_loss += loss.detach().cpu().numpy().item()\n",
    "\n",
    "                y_pred.extend(predictions.cpu().numpy())\n",
    "                y_true.extend(valid_labels.cpu().numpy())\n",
    "\n",
    "            valid_loss /= valid_step\n",
    "            f1 = f1_score(y_true,y_pred)\n",
    "\n",
    "            print(f'Epoch [{epoch+1}/{epochs}] Score: {f1}')\n",
    "            print(f'Epoch [{epoch+1}/{epochs}] Valid_loss: {valid_loss}')\n",
    "\n",
    "            if valid_loss < min(valid_loss_min):\n",
    "                print('model improved!')\n",
    "            else:\n",
    "                print('model not improved')\n",
    "    \n",
    "            torch.save(model.state_dict(), f'epoch:{epoch+1}_model.pt')\n",
    "            print('save checkpoint!')\n",
    "            valid_loss_min.append(valid_loss)\n",
    "            print(f'valid_loss_min:{min(valid_loss_min)}')\n",
    "        \n",
    "        # Double check your directory\n",
    "        best_model_epoch.append(f'save/bert-base/epoch:{epoch+1}_model.pt')\n",
    "        valid_loss_values.append(valid_loss)\n",
    "        print('='*100)\n",
    "\n",
    "    select_best_model() # refer to below function\n",
    "    print('Train/Valid Completed!!')\n",
    "    del train_dataloader, valid_dataloader # memory cleaning\n",
    "    gc.collect()\n",
    "\n",
    "def select_best_model():\n",
    "    best_model = best_model_epoch[np.array(valid_loss_values).argmin()]\n",
    "    os.rename(best_model, best_model.split('.pt')[0] + '_best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU is turning on...\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print('GPU is running on...')\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    print('CPU is running on...')\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Before training, files in current directory: {os.listdir()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Start!')\n",
    "print('=' * 100)\n",
    "\n",
    "train(model,\n",
    "    device,\n",
    "    train_dataloader,\n",
    "    valid_dataloader,\n",
    "    configs['epochs'],\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    metric)\n",
    "\n",
    "del model, train_dataloader, valid_dataloader\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'After training, files in current directory: {os.listdir()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model,test_dataloader):\n",
    "    all_preds = []\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_dataloader):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "\n",
    "            logits = model(input_ids,attention_mask)\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            all_preds.append(logits)\n",
    "    \n",
    "    return all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3140fc01d07b46409ff0654fcbff84f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3263 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for filename in os.listdir():\n",
    "    if 'best.pt' in filename: \n",
    "        best_pt = filename\n",
    "print(f'Best model.pt: {best_pt}')\n",
    "check_point = torch.load(best_pt)\n",
    "\n",
    "model = TweetsModel(configs['model_name']).to(device)\n",
    "model.to(device)\n",
    "model.load_state_dict(check_point)\n",
    "\n",
    "predictions = inference(model,test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  target\n",
       "0         0       0\n",
       "1         2       0\n",
       "2         3       0\n",
       "3         9       0\n",
       "4        11       0\n",
       "...     ...     ...\n",
       "3258  10861       0\n",
       "3259  10865       0\n",
       "3260  10868       0\n",
       "3261  10874       0\n",
       "3262  10875       0\n",
       "\n",
       "[3263 rows x 2 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = pd.read_csv('./Data/sample_submission.csv')\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       1\n",
       "1   2       1\n",
       "2   3       1\n",
       "3   9       1\n",
       "4  11       1\n",
       "5  12       1\n",
       "6  21       0\n",
       "7  22       0\n",
       "8  27       0\n",
       "9  29       0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.argmax(predictions,axis=2)\n",
    "sample['target'] = predictions\n",
    "sample.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv('submission.csv',index=False,header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7fecef7fb14ad1d71e869da5296badaba2a50d2b864b0443ebcc6afac654c29b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
